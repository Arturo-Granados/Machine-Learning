{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsVmfw+gE2iKGDbOrvMFQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arturo-Granados/Machine-Learning/blob/main/Homework_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 8: Deep learning "
      ],
      "metadata": {
        "id": "tpBfQ-5xYD2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this homework, we'll build a model for predicting if we have an image of a dino or a dragon. For this, we will use the \"Dino or Dragon?\" dataset that can be downloaded from [Kaggle](kaggle datasets download -d agrigorev/dino-or-dragon).\n"
      ],
      "metadata": {
        "id": "DgDUVTlbYKP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up"
      ],
      "metadata": {
        "id": "DwF2hWGiYbLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7NlcHA0fXeNB"
      },
      "outputs": [],
      "source": [
        "#Import the main libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get data"
      ],
      "metadata": {
        "id": "K3n07DCkYicj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import kaggle\n",
        "!pip install kaggle "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PByHAbCQYh2U",
        "outputId": "a96da100-fffd-41f3-9c4e-bf9b86ab8cf5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check my actual directory\n",
        "!pwd "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW9JHhnJYlh8",
        "outputId": "7b75a95b-3cb6-4b62-e8f3-4d355f40879b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import os module\n",
        "import os \n",
        "\n",
        "#Directory configuration\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content' "
      ],
      "metadata": {
        "id": "3L0ei15JYpaG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d agrigorev/dino-or-dragon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCfz9t7qYqDu",
        "outputId": "89814794-470a-46f6-cb74-229dc69fabfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dino-or-dragon.zip to /content\n",
            "100% 104M/104M [00:07<00:00, 12.6MB/s]\n",
            "100% 104M/104M [00:07<00:00, 13.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extrac data form the zip file"
      ],
      "metadata": {
        "id": "MGyVwl7pZNQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import ZipFile form zipfile\n",
        "from zipfile import ZipFile \n",
        "\n",
        "#Function to extra files from a zip file\n",
        "def open_zipfile(file_name): \n",
        "  with ZipFile(file_name, 'r') as zip:\n",
        "   \n",
        "    #zip.printdir() \n",
        "    zip.extractall() "
      ],
      "metadata": {
        "id": "uhIIca8cYxhZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the open_zipfile funtion to extract the csv files \n",
        "open_zipfile('dino-or-dragon.zip')"
      ],
      "metadata": {
        "id": "cm7NBI7NZPSi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "\n",
        "The dataset contains around 1900 images of dinos and around 1900 images of dragons.\n",
        "\n",
        "The dataset contains separate folders for training and validation."
      ],
      "metadata": {
        "id": "HM0thucpZE3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
        "\n",
        "You need to develop the model with following structure:\n",
        "\n",
        "* The shape for input should be `(150, 150, 3)`\n",
        "* Next, create a convolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
        "    * Use 32 filters\n",
        "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
        "    * Use `'relu'` as activation \n",
        "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
        "    * Set the pooling size to `(2, 2)`\n",
        "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
        "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
        "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
        "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
        "\n",
        "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
        "\n",
        "* `SGD(lr=0.002, momentum=0.8)`\n",
        "\n",
        "For clarification about kernel size and max pooling, check [Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc)."
      ],
      "metadata": {
        "id": "IIjLSUBkZlWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1\n",
        "\n",
        "Since we have a binary classification problem, what is the best loss function for us?\n",
        "\n",
        "- `binary crossentropy`\n",
        "- `focal loss`\n",
        "- `mean squared error`\n",
        "- `categorical crossentropy`\n",
        "\n",
        "Note: since we specify an activation for the output layer, we don't need to set `from_logits=True`"
      ],
      "metadata": {
        "id": "zD_XJ8QSaaQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer: binary crossentropy"
      ],
      "metadata": {
        "id": "JBvDiaBvcMjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2\n",
        "What's the total number of parameters of the model? You can use the summary method for that.\n",
        "\n",
        "* 9215873\n",
        "* 11215873\n",
        "* 14215873\n",
        "* 19215873"
      ],
      "metadata": {
        "id": "qawc5sCDcawb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries for CNN model \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "Bn0Ohdoxcl7y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  tf.keras.Sequential([\n",
        "    keras.layers.Conv2D(filters = 32,kernel_size = (3, 3), activation = 'relu', input_shape=(150, 150, 3)),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units = 64, activation = 'relu'),\n",
        "    keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "RqSdgcDgcacS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.SGD(lr=0.002, momentum=0.8),\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "0IHD1DHacMCP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNBuHjCQaZ6N",
        "outputId": "efd24f47-d2c1-4a4d-9c1a-34cece0d3be3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 175232)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                11214912  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,215,873\n",
            "Trainable params: 11,215,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Answer: 11,215,873"
      ],
      "metadata": {
        "id": "yKUZnq2PfjLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generators and Training\n",
        "\n",
        "For the next two questions, use the following data generator for both train and validation:\n",
        "\n",
        "```python\n",
        "ImageDataGenerator(rescale=1./255)\n",
        "```\n",
        "\n",
        "* We don't need to do any additional pre-processing for the images.\n",
        "* When reading the data from train/val directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
        "* Use `batch_size=20`\n",
        "* Use `shuffle=True` for both training and validation \n",
        "\n",
        "For training use `.fit()` with the following params:\n",
        "\n",
        "```python\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "nHjtvUQghOvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Def image generator\n",
        "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "LDV_ifpjhOWC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "#Def data paths\n",
        "train_dir = '/content/train'  \n",
        "test_dir = '/content/test'\n",
        "\n",
        "#Define train, test, validation data paths dir \n",
        "train_dir = pathlib.Path(train_dir)\n",
        "test_dir = pathlib.Path(test_dir)"
      ],
      "metadata": {
        "id": "8RHxkod-h-NV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Def train set \n",
        "train_ds = img_gen.flow_from_directory(train_dir,\n",
        "                                       target_size=(150, 150),\n",
        "                                       batch_size=20,\n",
        "                                       shuffle=True,\n",
        "                                       class_mode='binary')\n",
        "#Def tests set \n",
        "test_ds = img_gen.flow_from_directory(test_dir,\n",
        "                                      target_size=(150, 150),\n",
        "                                      batch_size=20,\n",
        "                                      shuffle=True,\n",
        "                                      class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMwR5ZFlfiz-",
        "outputId": "4a968f6a-d8ed-4af5-a12b-c96071b5aa05"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1594 images belonging to 2 classes.\n",
            "Found 394 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=10,\n",
        "    validation_data=test_ds\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm43Zf93aWos",
        "outputId": "7fe2a081-60e9-4ee4-ba0d-499bc2fcba0f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "80/80 [==============================] - 9s 113ms/step - loss: 0.5923 - accuracy: 0.6662 - val_loss: 0.4680 - val_accuracy: 0.8223\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 9s 111ms/step - loss: 0.4697 - accuracy: 0.7936 - val_loss: 0.4320 - val_accuracy: 0.8071\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 9s 111ms/step - loss: 0.3819 - accuracy: 0.8432 - val_loss: 0.3488 - val_accuracy: 0.8680\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 9s 111ms/step - loss: 0.3163 - accuracy: 0.8701 - val_loss: 0.3650 - val_accuracy: 0.8223\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 9s 111ms/step - loss: 0.3073 - accuracy: 0.8858 - val_loss: 0.3086 - val_accuracy: 0.8731\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 9s 111ms/step - loss: 0.2586 - accuracy: 0.9003 - val_loss: 0.2933 - val_accuracy: 0.8782\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 9s 112ms/step - loss: 0.2236 - accuracy: 0.9166 - val_loss: 0.3032 - val_accuracy: 0.8655\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 9s 111ms/step - loss: 0.1972 - accuracy: 0.9329 - val_loss: 0.2804 - val_accuracy: 0.8756\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 9s 110ms/step - loss: 0.1759 - accuracy: 0.9410 - val_loss: 0.2679 - val_accuracy: 0.8832\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 9s 113ms/step - loss: 0.1491 - accuracy: 0.9511 - val_loss: 0.2947 - val_accuracy: 0.8807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3\n",
        "\n",
        "What is the median of training accuracy for all the epochs for this model?\n",
        "\n",
        "- 0.40\n",
        "- 0.60\n",
        "- 0.90\n",
        "- 0.20\n"
      ],
      "metadata": {
        "id": "2GY_BsN0qISj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(history.history['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwbFTN-gi_-p",
        "outputId": "ee469df7-2040-4077-cf66-02fe016dffa1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8700752675533294"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4\n",
        "\n",
        "What is the standard deviation of training loss for all the epochs for this model?\n",
        "\n",
        "- 0.11\n",
        "- 0.66\n",
        "- 0.99\n",
        "- 0.33"
      ],
      "metadata": {
        "id": "Bp8COO1DqCqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znXGlPP8pYA0",
        "outputId": "7ec0896f-1fa9-468a-8361-44ea1ffec131"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13307542942969783"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation\n",
        "\n",
        "For the next two questions, we'll generate more data using data augmentations. \n",
        "\n",
        "Add the following augmentations to your training data generator:\n",
        "\n",
        "* `rotation_range=40,`\n",
        "* `width_shift_range=0.2,`\n",
        "* `height_shift_range=0.2,`\n",
        "* `shear_range=0.2,`\n",
        "* `zoom_range=0.2,`\n",
        "* `horizontal_flip=True,`\n",
        "* `fill_mode='nearest'"
      ],
      "metadata": {
        "id": "bKwmnizUs6RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ],
      "metadata": {
        "id": "kvc_9-l5seRV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "NMjq9JTduxxe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Def train set \n",
        "train_ds = train_data_generator.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=20,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIyToBeDuGZJ",
        "outputId": "294143b3-3cfa-4885-d51e-b1cbc0859866"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1594 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Def tests set \n",
        "test_ds = test_data_generator.flow_from_directory(test_dir,\n",
        "                                                  target_size=(150, 150),\n",
        "                                                  batch_size=20,\n",
        "                                                  shuffle=True,\n",
        "                                                  class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiLcR7vyw6ko",
        "outputId": "b39539b8-7aaf-4741-c363-e6be5bdcd832"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 394 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=10,\n",
        "    validation_data=test_ds,\n",
        "    validation_steps=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW9knLzIvSib",
        "outputId": "ee9a1579-a3ac-44ac-cd0e-4feb45a33eba"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "80/80 [==============================] - ETA: 0s - loss: 4154.8345 - accuracy: 0.5458"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r80/80 [==============================] - 16s 201ms/step - loss: 4154.8345 - accuracy: 0.5458 - val_loss: 126.2163 - val_accuracy: 0.4975\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 14s 170ms/step - loss: 0.7798 - accuracy: 0.5138\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 14s 170ms/step - loss: 0.6928 - accuracy: 0.5188\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 14s 171ms/step - loss: 0.6930 - accuracy: 0.5188\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 14s 169ms/step - loss: 0.6928 - accuracy: 0.5188\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 14s 170ms/step - loss: 0.6928 - accuracy: 0.5188\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 14s 173ms/step - loss: 0.6931 - accuracy: 0.5188\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 14s 170ms/step - loss: 0.6926 - accuracy: 0.5188\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 14s 171ms/step - loss: 0.6926 - accuracy: 0.5188\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 13s 168ms/step - loss: 0.6926 - accuracy: 0.5188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5 \n",
        "\n",
        "Let's train our model for 10 more epochs using the same code as previously.\n",
        "Make sure you don't re-create the model - we want to continue training the model\n",
        "we already started training.\n",
        "\n",
        "What is the mean of validation loss for all the epochs for the model trained with augmentations?\n",
        "\n",
        "- 0.15\n",
        "- 0.77\n",
        "- 0.37\n",
        "- 0.97"
      ],
      "metadata": {
        "id": "Qbs83fY-vtAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3XGXFvByE82",
        "outputId": "529bcc4a-f0d4-4dbc-ad34-4b53a9f58c00"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6\n",
        "\n",
        "What's the average of validation accuracy for the last 5 epochs (from 6 to 10)\n",
        "for the model trained with augmentations?\n",
        "\n",
        "- 0.84\n",
        "- 0.54\n",
        "- 0.44\n",
        "- 0.24"
      ],
      "metadata": {
        "id": "UdZkLhlzwD04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(history.history['accuracy'][5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOKRf628yF9x",
        "outputId": "4e2d94a2-87d5-4951-dbc5-7e146c9f69e8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.518820583820343"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0Imt7kPzjbU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}